{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "random.seed(45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, test_size):\n",
    "    \n",
    "    if isinstance(test_size, float):\n",
    "        test_size = round(test_size*len(df))#Calculating the test size \n",
    "\n",
    "    indices = df.index.tolist()\n",
    "    test_indices = random.sample(population = indices, k = test_size)#Random sampling of data\n",
    "\n",
    "    test_df = df.loc[test_indices]#Getting the test data set\n",
    "    train_df = df.drop(test_indices)#Getting the train data set\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_purity(data):\n",
    "    label_column = data[:, -1]\n",
    "    unique_classes = np.unique(label_column)\n",
    "\n",
    "    if(len(unique_classes)) == 1:#Only 1 target attribute present in data\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    \n",
    "    classification = np.mean(label_column)#Final classification of data as mean of all target attriutes present \n",
    "   \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_splits(data):#Getting all the potential points with which we can split data\n",
    "    potential_splits = {}\n",
    "    _, n_columns = data.shape\n",
    "    for column_index in range(n_columns - 1):\n",
    "        potential_splits[column_index] = []\n",
    "        values = data[:, column_index]\n",
    "        unique_values = np.unique(values)\n",
    "        \n",
    "        for index in range(len(unique_values)):\n",
    "            if index!=0:\n",
    "                current_value = unique_values[index]\n",
    "                previous_value = unique_values[index-1]\n",
    "                potential_split = (current_value+previous_value)/2\n",
    "                \n",
    "                potential_splits[column_index].append(potential_split)\n",
    "    \n",
    "    return potential_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, split_column, split_value):#Splitting data with the target attribute specified and target attribute vale\n",
    "    \n",
    "    split_column_values = data[:, split_column]\n",
    "    \n",
    "    data_below = data[split_column_values <= split_value]\n",
    "    data_above = data[split_column_values >= split_value]\n",
    "    \n",
    "    return data_below, data_above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Best Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mse(data):#Returns the mean squared error of the target attribute in dataset passed\n",
    "    \n",
    "    actual_values = data[:, -1]\n",
    "    \n",
    "    if len(actual_values) == 0: \n",
    "        mean_squared_error = 0\n",
    "    else :\n",
    "        prediction = np.mean(actual_values)\n",
    "        mean_squared_error = np.mean((actual_values - prediction)**2)\n",
    "    return mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_mse(data_below, data_above):#Calculate overall mse of the data_above and data_below\n",
    "    n_data_points = len(data_below) + len(data_above)\n",
    "    \n",
    "    p_data_below = len(data_below)/n_data_points\n",
    "    p_data_above = len(data_above)/n_data_points\n",
    "    \n",
    "    overall_mse = (p_data_below*calculate_mse(data_below)\n",
    "                      +p_data_above*calculate_mse(data_above))#Weighted average of mse of the 2 parts\n",
    "    \n",
    "    return overall_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_best_split(data, potential_splits, counter):\n",
    "    overall_mse = -1#Finding the best split that provides best reduction in overall mean squared error\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            data_below, data_above = split_data(data, split_column = column_index, split_value = value)\n",
    "            current_overall_mse = calculate_overall_mse(data_below, data_above)\n",
    "            if overall_mse < 0:\n",
    "                overall_mse = current_overall_mse\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "            elif counter%2 == 0 and (current_overall_mse < overall_mse):\n",
    "                overall_mse = current_overall_mse\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "            elif counter%2 == 1 and (current_overall_mse <= overall_mse):\n",
    "                overall_mse = current_overall_mse\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    if best_split_value == 0:\n",
    "        print(data)\n",
    "    return best_split_column, best_split_value#This is the best split returned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_algorithm(dataf, counter=0, max_depth = 10):\n",
    "    \n",
    "    if counter == 0:\n",
    "        global COLUMN_HEADERS\n",
    "        COLUMN_HEADERS = dataf.columns\n",
    "        data = dataf.values\n",
    "    else:\n",
    "        data = dataf\n",
    "    \n",
    "    #base case\n",
    "    #print(data)\n",
    "    if check_purity(data):\n",
    "        #print(True)\n",
    "        classification = classify_data(data)\n",
    "        return classification\n",
    "    elif counter >= max_depth and max_depth>0:\n",
    "        classification = classify_data(data)\n",
    "        return classification\n",
    "    #recursive part\n",
    "    else:\n",
    "        counter+=1\n",
    "        \n",
    "        #helper functions\n",
    "        potential_splits = get_potential_splits(data)\n",
    "        split_column, split_value = determine_best_split(data, potential_splits, counter)\n",
    "        data_below, data_above = split_data(data, split_column,split_value)\n",
    "        \n",
    "        #print(\"split_column {}, split_value {}\".format(split_column, split_value))\n",
    "        if len(data_below)==0 or len(data_above)==0:\n",
    "            classification = classify_data(data)\n",
    "            return classification\n",
    "        #instantiate sub-tree\n",
    "        feature_name = COLUMN_HEADERS[split_column]\n",
    "        question = \"{} <= {}\".format(feature_name, split_value)\n",
    "        sub_tree = {question: []}\n",
    "        \n",
    "        #find answers (recursion)\n",
    "        yes_answer = decision_tree_algorithm(data_below, counter, max_depth)\n",
    "        no_answer = decision_tree_algorithm(data_above, counter, max_depth)\n",
    "        \n",
    "        if yes_answer == no_answer:\n",
    "            sub_tree = yes_answer\n",
    "        else:\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "        \n",
    "        return sub_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_example(example, tree):#Predicting final value of unseen example with given tree\n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, value = question.split()\n",
    "    #print(example[feature_name])\n",
    "    if example[feature_name] <= float(value):\n",
    "        answer = tree[question][0]\n",
    "        #print(answer)\n",
    "    else:\n",
    "        answer = tree[question][1]\n",
    "        #print(answer)\n",
    "    #base case\n",
    "    if not isinstance(answer, dict):\n",
    "        return float(answer)\n",
    "    #Recursive Call\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return classify_example(example, residual_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_r_squared(df, tree):#Measure of accuracy \n",
    "    labels = df.label\n",
    "    mean = labels.mean()\n",
    "    predictions = df.apply(classify_example, args=(tree,), axis = 1)\n",
    "    \n",
    "    ss_res = sum((labels-predictions)**2)\n",
    "    ss_tot = sum((labels-mean)**2)\n",
    "    r_squared = 1 - ss_res/ss_tot\n",
    "    \n",
    "    return r_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree():\n",
    "    df = pd.read_csv(\"PercentageIncreaseCOVIDWorldwide.csv\")\n",
    "    df = df.drop(\"Date\", axis = 1)\n",
    "    df = df.rename(columns = {\"Increase rate\": \"label\"})\n",
    "    df = df.drop(df.index[0])\n",
    "    print(\"Enter Maximum Depth\")\n",
    "    max = input()\n",
    "    r_squared = 0.00\n",
    "    for i in range(10):#Finding the best split over 10 random 80:20 splits \n",
    "        train_val_df, test_df = train_test_split(df, test_size = 0.2)\n",
    "        train_df, val_df = train_test_split(train_val_df, test_size = 0.25)\n",
    "        tree = decision_tree_algorithm(train_df, counter = 0, max_depth = int(max))\n",
    "        r_squared_train = calculate_r_squared(train_df, tree)\n",
    "        r_squared_test = calculate_r_squared(test_df, tree)\n",
    "        if r_squared_test > r_squared:#Finding the split offering best test accuracy\n",
    "            r_squared = r_squared_test\n",
    "            train_df_best = train_df\n",
    "            test_df_best = test_df\n",
    "            val_df_best = val_df\n",
    "            \n",
    "    return train_df_best, test_df_best, val_df_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Maximum Depth\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "train_df_best, test_df_best, val_df_best = build_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Iteration 1/10\n",
      "Progress: Iteration 2/10\n",
      "Progress: Iteration 3/10\n",
      "Progress: Iteration 4/10\n",
      "Progress: Iteration 5/10\n",
      "Progress: Iteration 6/10\n",
      "Progress: Iteration 7/10\n",
      "Progress: Iteration 8/10\n",
      "Progress: Iteration 9/10\n",
      "Progress: Iteration 10/10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>r_squared_train</th>\n",
       "      <th>r_squared_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.778993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.997140</td>\n",
       "      <td>0.778417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999582</td>\n",
       "      <td>0.778260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999785</td>\n",
       "      <td>0.778253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.777870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.975295</td>\n",
       "      <td>0.748259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.986054</td>\n",
       "      <td>0.740042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.907342</td>\n",
       "      <td>0.648440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.855019</td>\n",
       "      <td>0.629770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.609444</td>\n",
       "      <td>0.459665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  r_squared_train  r_squared_test\n",
       "6          7         0.998859        0.778993\n",
       "5          6         0.997140        0.778417\n",
       "7          8         0.999582        0.778260\n",
       "8          9         0.999785        0.778253\n",
       "9         10         0.999922        0.777870\n",
       "3          4         0.975295        0.748259\n",
       "4          5         0.986054        0.740042\n",
       "2          3         0.907342        0.648440\n",
       "1          2         0.855019        0.629770\n",
       "0          1         0.609444        0.459665"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = {\"max_depth\": [],  \"r_squared_train\": [], \"r_squared_test\": []}\n",
    "\n",
    "for max_depth in range (1,11):#Recording train and test error over different max depths\n",
    "    tree = decision_tree_algorithm(train_df_best, counter = 0, max_depth = max_depth)\n",
    "    r_squared_train = calculate_r_squared(train_df_best, tree)\n",
    "    r_squared_test = calculate_r_squared(test_df_best, tree)\n",
    "    r_squared_val = calculate_r_squared(val_df_best, tree)    \n",
    "    \n",
    "    grid_search[\"max_depth\"].append(max_depth)\n",
    "    grid_search[\"r_squared_train\"].append(r_squared_train)\n",
    "    grid_search[\"r_squared_test\"].append(r_squared_test)\n",
    "    \n",
    "    print(\"Progress: Iteration {}/10\".format(max_depth))\n",
    "    \n",
    "grid_search = pd.DataFrame(grid_search)\n",
    "grid_search.sort_values(\"r_squared_test\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d78c962b08>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(grid_search[\"max_depth\"], grid_search[\"r_squared_train\"], label = 'Training Accuracy')\n",
    "plt.plot(grid_search[\"max_depth\"], grid_search[\"r_squared_test\"], label = 'Test_accuracy')\n",
    "plt.xlabel(\"Height\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Depth of the tree for which test accuracy is maximum is : 7\n"
     ]
    }
   ],
   "source": [
    "max_accuracy = grid_search[\"r_squared_test\"][0]\n",
    "best_depth = 1\n",
    "for i in range(0, len(grid_search[\"r_squared_test\"])):\n",
    "    if grid_search[\"r_squared_test\"][i] >= max_accuracy:\n",
    "        max_accuracy = grid_search[\"r_squared_test\"][i]\n",
    "        best_depth = i+1\n",
    "\n",
    "print(\"Best Depth of the tree for which test accuracy is maximum is : {}\".format(best_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_best = decision_tree_algorithm(train_df_best, counter = 0, max_depth = best_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_pruning(tree, df_train, df_val):\n",
    "    \n",
    "    question = list(tree.keys())[0]\n",
    "    #print(question)\n",
    "    yes_answer, no_answer = tree[question]\n",
    "    #base case\n",
    "    if not isinstance(yes_answer, dict) and not isinstance(no_answer, dict):\n",
    "        prediction = df_train.label.mean()\n",
    "        leaf = prediction\n",
    "        new_tree = {question : [prediction, prediction]}\n",
    "        if df_train.shape[0]<=1 or df_val.shape[0] <= 1:\n",
    "            return tree\n",
    "        accuracy_leaf = calculate_r_squared(df_val, new_tree)\n",
    "        accuracy_tree = calculate_r_squared(df_val, tree)\n",
    "        \n",
    "        if accuracy_leaf >= accuracy_tree:#if post-pruning accuracy > pre-pruning accuracy\n",
    "            print(\"trimmed at node {}\".format(question))#To check which nodes are trimmed\n",
    "            return prediction\n",
    "        else:\n",
    "            return tree\n",
    "    # Recursive part\n",
    "    else:\n",
    "        feature, _, value = question.split()\n",
    "        df_train_yes = df_train[df_train[feature] <= float(value)]\n",
    "        df_train_no = df_train[df_train[feature] > float(value)]\n",
    "        df_val_yes = df_val[df_val[feature] <= float(value)]\n",
    "        df_val_no = df_val[df_val[feature] > float(value)]\n",
    "        \n",
    "        if isinstance(yes_answer, dict):#Non leaf\n",
    "            tree[question][0] = post_pruning(yes_answer, df_train_yes, df_val_yes)\n",
    "        \n",
    "        if isinstance(no_answer, dict):#Non leaf\n",
    "            tree[question][1] = post_pruning(no_answer, df_train_no, df_val_no)\n",
    "            \n",
    "        return tree\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trimmed at node Deaths <= 54.0\n",
      "trimmed at node Deaths <= 474925.0\n",
      "trimmed at node Deaths <= 848444.0\n"
     ]
    }
   ],
   "source": [
    "tree_best_pruned = post_pruning(tree_best, train_df_best, val_df_best)#Pruning the tree\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Deaths <= 563.0\n",
      " (True) \n",
      "\t Confirmed <= 4546.5\n",
      "\t (True) \n",
      "\t Predicted Rate = 41.040101879999995\n",
      "\t (False) \n",
      "\t\t Deaths <= 173.0\n",
      "\t\t (True) \n",
      "\t\t Predicted Rate = 10.54141269\n",
      "\t\t (False) \n",
      "\t\t\t Confirmed <= 17968.0\n",
      "\t\t\t (True) \n",
      "\t\t\t\t Deaths <= 236.0\n",
      "\t\t\t\t (True) \n",
      "\t\t\t\t Predicted Rate = 20.54894341\n",
      "\t\t\t\t (False) \n",
      "\t\t\t\t Predicted Rate = 21.27745315\n",
      "\t\t\t (False) \n",
      "\t\t\t Predicted Rate = 20.16895459\n",
      " (False) \n",
      "\t Confirmed <= 2288578.5\n",
      "\t (True) \n",
      "\t\t Deaths <= 4299.0\n",
      "\t\t (True) \n",
      "\t\t\t Confirmed <= 67979.0\n",
      "\t\t\t (True) \n",
      "\t\t\t\t Deaths <= 762.5\n",
      "\t\t\t\t (True) \n",
      "\t\t\t\t\t Confirmed <= 32598.5\n",
      "\t\t\t\t\t (True) \n",
      "\t\t\t\t\t Predicted Rate = 11.42784792\n",
      "\t\t\t\t\t (False) \n",
      "\t\t\t\t\t Predicted Rate = 11.66482696\n",
      "\t\t\t\t (False) \n",
      "\t\t\t\t\t Confirmed <= 55859.0\n",
      "\t\t\t\t\t (True) \n",
      "\t\t\t\t\t\t Deaths <= 1063.0\n",
      "\t\t\t\t\t\t (True) \n",
      "\t\t\t\t\t\t Predicted Rate = 7.222752743\n",
      "\t\t\t\t\t\t (False) \n",
      "\t\t\t\t\t\t Predicted Rate = 4.77459783\n",
      "\t\t\t\t\t (False) \n",
      "\t\t\t\t\t Predicted Rate = 10.80969179\n",
      "\t\t\t (False) \n",
      "\t\t\t\t Deaths <= 1995.5\n",
      "\t\t\t\t (True) \n",
      "\t\t\t\t\t Confirmed <= 72251.5\n",
      "\t\t\t\t\t (True) \n",
      "\t\t\t\t\t\t Deaths <= 1718.0\n",
      "\t\t\t\t\t\t (True) \n",
      "\t\t\t\t\t\t Predicted Rate = 3.2014108930000003\n",
      "\t\t\t\t\t\t (False) \n",
      "\t\t\t\t\t\t Predicted Rate = 3.162925416\n",
      "\t\t\t\t\t (False) \n",
      "\t\t\t\t\t Predicted Rate = 2.8567818739999997\n",
      "\t\t\t\t (False) \n",
      "\t\t\t\t\t Confirmed <= 84374.0\n",
      "\t\t\t\t\t (True) \n",
      "\t\t\t\t\t\t Deaths <= 2740.5\n",
      "\t\t\t\t\t\t (True) \n",
      "\t\t\t\t\t\t Predicted Rate = 0.8034706933999999\n",
      "\t\t\t\t\t\t (False) \n",
      "\t\t\t\t\t\t Predicted Rate = 1.44323966\n",
      "\t\t\t\t\t (False) \n",
      "\t\t\t\t\t\t Deaths <= 3491.5\n",
      "\t\t\t\t\t\t (True) \n",
      "\t\t\t\t\t\t Predicted Rate = 2.509852726\n",
      "\t\t\t\t\t\t (False) \n",
      "\t\t\t\t\t\t Predicted Rate = 3.5938650639999996\n",
      "\t\t (False) \n",
      "\t\t\t Confirmed <= 1433349.5\n",
      "\t\t\t (True) \n",
      "\t\t\t\t Deaths <= 9712.0\n",
      "\t\t\t\t (True) \n",
      "\t\t\t\t\t Confirmed <= 184211.5\n",
      "\t\t\t\t\t (True) \n",
      "\t\t\t\t\t\t Deaths <= 5543.0\n",
      "\t\t\t\t\t\t (True) \n",
      "\t\t\t\t\t\t Predicted Rate = 6.479107652000001\n",
      "\t\t\t\t\t\t (False) \n",
      "\t\t\t\t\t\t Predicted Rate = 7.117191906\n",
      "\t\t\t\t\t (False) \n",
      "\t\t\t\t\t Predicted Rate = 8.555235548999999\n",
      "\t\t\t\t (False) \n",
      "\t\t\t\t\t Confirmed <= 701460.0\n",
      "\t\t\t\t\t (True) \n",
      "\t\t\t\t\t\t Deaths <= 28497.5\n",
      "\t\t\t\t\t\t (True) \n",
      "\t\t\t\t\t\t Predicted Rate = 11.993221004\n",
      "\t\t\t\t\t\t (False) \n",
      "\t\t\t\t\t\t Predicted Rate = 11.21739994\n",
      "\t\t\t\t\t (False) \n",
      "\t\t\t\t\t\t Deaths <= 62226.0\n",
      "\t\t\t\t\t\t (True) \n",
      "\t\t\t\t\t\t Predicted Rate = 8.767461428666666\n",
      "\t\t\t\t\t\t (False) \n",
      "\t\t\t\t\t\t Predicted Rate = 7.232104118\n",
      "\t\t\t (False) \n",
      "\t\t\t\t Deaths <= 118608.0\n",
      "\t\t\t\t (True) \n",
      "\t\t\t\t Predicted Rate = 5.519138332000001\n",
      "\t\t\t\t (False) \n",
      "\t\t\t\t\t Confirmed <= 2026764.5\n",
      "\t\t\t\t\t (True) \n",
      "\t\t\t\t\t\t Deaths <= 131077.0\n",
      "\t\t\t\t\t\t (True) \n",
      "\t\t\t\t\t\t Predicted Rate = 3.771078812\n",
      "\t\t\t\t\t\t (False) \n",
      "\t\t\t\t\t\t Predicted Rate = 3.6431678339999998\n",
      "\t\t\t\t\t (False) \n",
      "\t\t\t\t\t\t Deaths <= 154404.5\n",
      "\t\t\t\t\t\t (True) \n",
      "\t\t\t\t\t\t Predicted Rate = 4.376766493\n",
      "\t\t\t\t\t\t (False) \n",
      "\t\t\t\t\t\t Predicted Rate = 4.05422329\n",
      "\t (False) \n",
      "\t\t Deaths <= 316068.0\n",
      "\t\t (True) \n",
      "\t\t\t Confirmed <= 2928686.0\n",
      "\t\t\t (True) \n",
      "\t\t\t\t Deaths <= 199813.5\n",
      "\t\t\t\t (True) \n",
      "\t\t\t\t\t Confirmed <= 2365769.5\n",
      "\t\t\t\t\t (True) \n",
      "\t\t\t\t\t Predicted Rate = 3.278141754\n",
      "\t\t\t\t\t (False) \n",
      "\t\t\t\t\t\t Deaths <= 183173.5\n",
      "\t\t\t\t\t\t (True) \n",
      "\t\t\t\t\t\t Predicted Rate = 3.464610608\n",
      "\t\t\t\t\t\t (False) \n",
      "\t\t\t\t\t\t Predicted Rate = 3.374216928\n",
      "\t\t\t\t (False) \n",
      "\t\t\t\t\t Confirmed <= 2849895.5\n",
      "\t\t\t\t\t (True) \n",
      "\t\t\t\t\t Predicted Rate = 3.194609391\n",
      "\t\t\t\t\t (False) \n",
      "\t\t\t\t\t Predicted Rate = 3.020521853\n",
      "\t\t\t (False) \n",
      "\t\t\t\t Deaths <= 280170.5\n",
      "\t\t\t\t (True) \n",
      "\t\t\t\t\t Confirmed <= 3477511.0\n",
      "\t\t\t\t\t (True) \n",
      "\t\t\t\t\t\t Deaths <= 215045.0\n",
      "\t\t\t\t\t\t (True) \n",
      "\t\t\t\t\t\t Predicted Rate = 2.51633996\n",
      "\t\t\t\t\t\t (False) \n",
      "\t\t\t\t\t\t Predicted Rate = 2.4292759667499997\n",
      "\t\t\t\t\t (False) \n",
      "\t\t\t\t\t\t Deaths <= 263995.5\n",
      "\t\t\t\t\t\t (True) \n",
      "\t\t\t\t\t\t Predicted Rate = 2.218453483\n",
      "\t\t\t\t\t\t (False) \n",
      "\t\t\t\t\t\t Predicted Rate = 2.414896029\n",
      "\t\t\t\t (False) \n",
      "\t\t\t\t\t Confirmed <= 4356324.0\n",
      "\t\t\t\t\t (True) \n",
      "\t\t\t\t\t\t Deaths <= 285820.5\n",
      "\t\t\t\t\t\t (True) \n",
      "\t\t\t\t\t\t Predicted Rate = 2.1731875730000003\n",
      "\t\t\t\t\t\t (False) \n",
      "\t\t\t\t\t\t Predicted Rate = 1.9309993065\n",
      "\t\t\t\t\t (False) \n",
      "\t\t\t\t\t\t Deaths <= 312364.0\n",
      "\t\t\t\t\t\t (True) \n",
      "\t\t\t\t\t\t Predicted Rate = 2.199897331\n",
      "\t\t\t\t\t\t (False) \n",
      "\t\t\t\t\t\t Predicted Rate = 2.0976246069999998\n",
      "\t\t (False) \n",
      "\t\t\t Confirmed <= 17722066.5\n",
      "\t\t\t (True) \n",
      "\t\t\t\t Deaths <= 404486.0\n",
      "\t\t\t\t (True) \n",
      "\t\t\t\t\t Confirmed <= 4809898.0\n",
      "\t\t\t\t\t (True) \n",
      "\t\t\t\t\t Predicted Rate = 1.688157911\n",
      "\t\t\t\t\t (False) \n",
      "\t\t\t\t\t\t Deaths <= 346306.0\n",
      "\t\t\t\t\t\t (True) \n",
      "\t\t\t\t\t\t Predicted Rate = 2.0639206045\n",
      "\t\t\t\t\t\t (False) \n",
      "\t\t\t\t\t\t Predicted Rate = 1.871311985\n",
      "\t\t\t\t (False) \n",
      "\t\t\t\t\t Confirmed <= 16023576.5\n",
      "\t\t\t\t\t (True) \n",
      "\t\t\t\t\t Predicted Rate = 1.710771092931035\n",
      "\t\t\t\t\t (False) \n",
      "\t\t\t\t\t\t Deaths <= 653389.0\n",
      "\t\t\t\t\t\t (True) \n",
      "\t\t\t\t\t\t Predicted Rate = 1.3602013144999998\n",
      "\t\t\t\t\t\t (False) \n",
      "\t\t\t\t\t\t Predicted Rate = 1.6459402247500001\n",
      "\t\t\t (False) \n",
      "\t\t\t\t Deaths <= 751553.0\n",
      "\t\t\t\t (True) \n",
      "\t\t\t\t\t Confirmed <= 19746667.0\n",
      "\t\t\t\t\t (True) \n",
      "\t\t\t\t\t\t Deaths <= 692876.0\n",
      "\t\t\t\t\t\t (True) \n",
      "\t\t\t\t\t\t Predicted Rate = 1.2760620916666667\n",
      "\t\t\t\t\t\t (False) \n",
      "\t\t\t\t\t\t Predicted Rate = 1.4091056983333334\n",
      "\t\t\t\t\t (False) \n",
      "\t\t\t\t\t\t Deaths <= 731715.0\n",
      "\t\t\t\t\t\t (True) \n",
      "\t\t\t\t\t\t Predicted Rate = 1.142119842\n",
      "\t\t\t\t\t\t (False) \n",
      "\t\t\t\t\t\t Predicted Rate = 1.268661992\n",
      "\t\t\t\t (False) \n",
      "\t\t\t\t\t Confirmed <= 24837826.5\n",
      "\t\t\t\t\t (True) \n",
      "\t\t\t\t\t\t Deaths <= 822538.0\n",
      "\t\t\t\t\t\t (True) \n",
      "\t\t\t\t\t\t Predicted Rate = 1.080263649625\n",
      "\t\t\t\t\t\t (False) \n",
      "\t\t\t\t\t\t Predicted Rate = 1.180057406\n",
      "\t\t\t\t\t (False) \n",
      "\t\t\t\t\t Predicted Rate = 1.0137175626000001\n"
     ]
    }
   ],
   "source": [
    "class PrintTree:#Printing the tree\n",
    "    def printTree(self, tree, d = 0):\n",
    "        if (tree == None or len(tree) == 0):\n",
    "            print(\"\\t\" * d, \"-\")\n",
    "        else:\n",
    "            for key, val in tree.items():\n",
    "                    print (\"\\t\" * d, key)\n",
    "                    for j in val:\n",
    "                        if j==val[0]:\n",
    "                            print(\"\\t\" * d,\"(True) \")\n",
    "                        else: \n",
    "                            print(\"\\t\" * d,\"(False) \")\n",
    "                        if isinstance(j,dict):\n",
    "                            self.printTree(j, d+1)\n",
    "                        else:\n",
    "                            if j==val[0]:\n",
    "                                print (\"\\t\" * d, \"Predicted Rate =\",j)\n",
    "                            else:\n",
    "                                print (\"\\t\" * d, \"Predicted Rate =\",j)\n",
    "\n",
    "final_tree=PrintTree()\n",
    "#pprint(tree_best_pruned)\n",
    "final_tree.printTree(tree_best_pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Test Accuracy: 0.7892350142716837 \n"
     ]
    }
   ],
   "source": [
    "r_squared_test = calculate_r_squared(test_df_best, tree_best_pruned)\n",
    "print(\"New Test Accuracy: {} \".format(r_squared_test))#Displaying new test accuracy post pruning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
